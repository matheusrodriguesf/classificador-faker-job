{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pós-graduação em Ciência de Dados e Machine Learning\n",
    "\n",
    "#### Módulo 3 - Data Mining e Machine Learning\n",
    "\n",
    "#### Disciplina: **Introdução a Aprendizagem De Máquina**\n",
    "\n",
    "#### Turma: **A**\n",
    "\n",
    "#### Projeto Final para disciplina Introdução a Aprendizagem De Máquina\n",
    "\n",
    "<BR>\n",
    "    \n",
    "#### Nome do Integrante: Matheus Rodrigues Fernandes Arcelino    RA: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição do Problema\n",
    "\n",
    "*Faker JobPost* é um dataset obtido em: https://www.kaggle.com/shivamb/real-or-fake-fake-jobposting-prediction.\n",
    "\n",
    "A presente base de dados, contém informações a respeito de anuncios de empregos considerados como *faker* ou *não faker*.\n",
    "\n",
    "O processo de buscar por um novo emprego ou adentrar no mercado de trabalho atualmente não se encontra fácil. Seja pelo fato do mercado de trabalho concorrente, requisitos de vagas que busca profissional experiente e qualificados uma das mais diversas variáveis presentes na vida de ser humano. Muitos golpes envolvem anúncios de emprego falsos com o objetivo de roubar informações pessoais tem sido uma realidade. O presente trabalho tem como objeto realizar um estudo de caso de como soluções computacionais pode nos ajudar a identificar anuncios de empregos falsos.\n",
    "\n",
    "**Pergunta de pesquisa:** Com técnicas de aprendizado de máquina e algoritmos de classificação podem ajudar na deteção de anúncios de emprego falso ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo\n",
    "\n",
    "Qual o motivo da escolha do algoritmo para resolver este problema ?\n",
    "\n",
    "Para a resolução do problema foi aplicado a técnica de aprendizado de máquina supervisionado, ou seja o dados forma previamente categorizados por um ser humano.\n",
    "\n",
    "A abordagem escolhida foi de classificação.\n",
    "\n",
    "Algoritmos escolhidos formam:\n",
    "\n",
    " - Naive Bayes\n",
    " - Support Vector Machine (SVM)\n",
    " - Decision Tree\n",
    " - Random Forest\n",
    " - Gradient boosting\n",
    " - K Nearest Neighbor (KNN)\n",
    "\n",
    "No que diz respeito a escolha dos algoritmos, a presente pesquisa tem como objetivo verificar o nível de eficiência e performance dos mesmos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação de bibliotecas auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar esse célula caso não tenha as bibliotecas xgboost e wordcloud instalado\n",
    "!pip install xgboost\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação da bibliotecas necessárias para EDA e técnicas de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings as warn\n",
    "import nltk\n",
    "import dask\n",
    "import joblib\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from unicodedata import normalize\n",
    "from dask.distributed import Client\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "\n",
    "nltk.download('punkt')\n",
    "warn.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e carregamento dos dados em Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_job = pd.read_csv('data/fake_job_postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir as 5 primeiras linhas do Dataframe\n",
    "fake_job.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir as 5 últimas linhas do Dataframe\n",
    "fake_job.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando tipos de dados\n",
    "\n",
    "O processo de verificação dos tipos de dados tem como objetivo realizar uma análise prévia de como os dados estão estruturados e se é necessário fazer alguma transformação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_job.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo colunas irrelevantes \n",
    "\n",
    "A etapa de remoção de colunas tem como objetivo remover colunas que para a presente análise não serão utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_job = fake_job.drop(['job_id','title',\n",
    "                          'location','department',\n",
    "                          'salary_range','company_profile',\n",
    "                          'requirements','benefits',\n",
    "                          'telecommuting','has_company_logo',\n",
    "                          'has_questions'],axis=1)\n",
    "fake_job.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo linhas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_job[fake_job.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_job = fake_job.drop_duplicates()\n",
    "fake_job.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminando os valores ausentes ou nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_job.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_job = fake_job.dropna()\n",
    "fake_job.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise exploratória de dados (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_job.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_job.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotagem de gráficos em diferentes features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de barra referente a coluna de classificação fraudulento (fraudulent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=fake_job.fraudulent.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(data=fake_job,x='fraudulent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de barra refente a coluna tipo de emprego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(data=fake_job,x='employment_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções axiliar para a plotagem de gráficos\n",
    "def grafico_pizza(df, atributo):\n",
    "    serie = df[atributo]\n",
    "    value_counts = serie.value_counts()\n",
    "    total = serie.count()\n",
    "    frequencia = (value_counts/total) *100\n",
    "    labels = serie.unique()\n",
    "    colors = ['#A43820', '#FFF8C6', '#99C68E', '#4DBCD3']\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.pie(frequencia, labels=labels ,  autopct='%1.1f%%', colors=colors,\n",
    "            shadow=True)\n",
    "    \n",
    "def grafico_barra_horizontal(df, y_value, order_value):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.countplot(data=df,y=y_value,order=order_value)\n",
    "    \n",
    "    \n",
    "def grafico_barra_vertical(df, atributo, length):\n",
    "    serie = fake_job.filter([atributo],axis=1)\n",
    "    serie['count'] = 1\n",
    "    serie = serie.groupby(atributo,as_index=False, sort=False).sum()\n",
    "    serie = serie.sort_values(\"count\",ascending=False)\n",
    "    serie = serie.head(length)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.barplot(data=serie,x=atributo,y='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de pizza referente ao percentual de experiência exigida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_pizza(df=fake_job,atributo='required_experience')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de barras requisitos Educacionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_barra_vertical(df=fake_job,atributo='required_education', length=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de barras Tipo de Indústria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_barra_horizontal(df=fake_job,y_value='industry',order_value=fake_job.industry.value_counts().iloc[:20].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de barras Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_barra_vertical(df=fake_job, atributo='function',length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico para verificar as palavras que mais se repetem na coluna descrição (description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_font_size=50, max_words=100,width=600, height=400,).generate(' '.join(fake_job.description))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento e transformação das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expressão regular para remover caracteres especiais\n",
    "# Remover qualquer tipo de caracter que não seja letra ou numero\n",
    "def remover_caracter_especial(texto):\n",
    "    return re.sub('[^a-zA-Z0-9 \\\\\\]', '', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização e tratamento dos dados\n",
    "fake_job['description'] = fake_job.apply(lambda row :normalize('NFKD', row['description']).encode('ASCII', 'ignore').decode('ASCII'),axis=1)\n",
    "fake_job['description'] = fake_job['description'].apply(remover_caracter_especial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(stopwords=stopwords,width=600, height=400, max_font_size=50, max_words=100,background_color=\"white\").generate(' '.join(fake_job.description))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagem de caracteres de cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Está célula cria uma nova coluna contando todos os caracteres presentes no atributo descrição. \n",
    "fake_job['size'] = fake_job.apply(lambda row: len(row.description), axis=1)\n",
    "fake_job.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma coluna e transforma cada os elementos do texto em token \n",
    "fake_job['tokens'] = fake_job.apply(lambda row: nltk.word_tokenize(row['description']), axis=1)\n",
    "fake_job.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração do features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(fake_job.description)\n",
    "y = fake_job.fraudulent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz TF-IDF dos termos\n",
    "\n",
    "A matriz TF-IDF tem como objetivo indicar a importância de uma palavra dentro de um conjunto de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todense = X.todense()\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "tfidf = pd.DataFrame(todense, columns=feature_names).T\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos Dataset em treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report(value_test, pred):\n",
    "    print(classification_report(value_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matrix_confusion(value_test, pred):\n",
    "    print(confusion_matrix(value_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acuracy_score = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visando encontrar o melhor algoritmo foram testados três implementações do *naive bayes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulling = BernoulliNB()\n",
    "bernoulling.fit(X_train, y_train)\n",
    "predict = bernoulling.predict(X_test)\n",
    "print_classification_report(value_test=y_test,pred=predict)\n",
    "print_matrix_confusion(value_test=y_test,pred=predict)\n",
    "list_acuracy_score.append(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complement_nb = ComplementNB()\n",
    "complement_nb.fit(X_train, y_train)\n",
    "predict = complement_nb.predict(X_test)\n",
    "print_classification_report(value_test=y_test,pred=predict)\n",
    "print_matrix_confusion(value_test=y_test,pred=predict)\n",
    "list_acuracy_score.append(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_nb = MultinomialNB()\n",
    "multinomial_nb.fit(X_train, y_train)\n",
    "predict = multinomial_nb.predict(X_test)\n",
    "print_classification_report(value_test=y_test,pred=predict)\n",
    "list_acuracy_score.append(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acuracy_score\n",
    "naives = ['BernoulliNB','ComplementNB','MultinomialNB']\n",
    "y_pos = np.arange(len(naives))\n",
    "y_val = [ x for x in list_acuracy_score]\n",
    "plt.bar(y_pos,y_val, align='center', alpha=0.7)\n",
    "plt.xticks(y_pos, naives)\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Accuracy of Models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme vimos no gráfico as três implementações do algoritmo *bayes* apresetaram o mesmo resultado.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliação dos resultados do modelo:**\n",
    " - Acurácia: Ambas as implementações do algoritmo *bayes* apresentaram um resultado ótimo de acurácia 0.96\n",
    " - Precisão: Ambas as implementações do algoritmo *bayes* apresentaram como correta para 0 0.97 e para 1 0.00        \n",
    " - Recall: Ambas as implementações do algoritmo *bayes* apresentaram como correta para 0: 1.00 e para 1:0.00\n",
    " - f1 score: Ambas as implementações do algoritmo *bayes* apresentaram como média harmonica: 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "predict = svm.predict(X_test)\n",
    "print_classification_report(value_test=y_test,pred=predict)\n",
    "print_matrix_confusion(value_test=y_test, pred=predict)\n",
    "list_acuracy_score.append(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliação dos resultados do modelo:**\n",
    " - Acurácia: O algoritmo *svm* apresentou um resultado ótimo de acurácia 0.97\n",
    " - Precisão: O algoritmo *svm* apresentou como correta para 0 0.97 e para 1 1.00        \n",
    " - Recall:   O algoritmo *svm* apresentou como correta para 0: 1.00 e para 1:0.14\n",
    " - f1 score: O algoritmo *svm* apresentou como média harmonica: 0.98 para 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros = {'C': [0.1, 1, 10, 100, 1000], \n",
    "                   'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                   'kernel': ['rbf']\n",
    "                  }\n",
    "print(hiperparametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Algoritmo de *Support Vector Machine (SVM)* apresentou uma acurácia ótima aceitável.\n",
    "Abaixo temos a implementação do **GridSearchCV** para verificar se encontramos parametros melhores para o SVM.\n",
    "\n",
    "\n",
    "**AVISO: VAI DEMORAR EXECUTAR ELE**. Para a melhoria de performace, foi implementado o processamento paralelo utilizando a biblioteca `dask`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute está célula para executar o grid search normal e tenha muita paciência \n",
    "grid = GridSearchCV(SVC(), hiperparametros, refit=True, verbose=3,cv=[(slice(None), slice(None))])\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute está célula para executar o grid search utilizando o processamento paralelo tenha paciência \n",
    "client = Client()\n",
    "with joblib.parallel_backend('dask'):\n",
    "    grid = GridSearchCV(SVC(), hiperparametros, refit=True, verbose=3)\n",
    "    grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_\n",
    "predict = grid.predict(X_test)\n",
    "print_classification_report(value_test=y_test,pred=predict)\n",
    "print_matrix_confusion(value_test=y_test,pred=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=1000, gamma=0.01, kernel='rbf') \n",
    "svm.fit(X_train, y_train)\n",
    "predict = svm.predict(X_test)\n",
    "print_classification_report(value_test=y_test,pred=predict)\n",
    "print_matrix_confusion(value_test=y_test,pred=predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "predict = decision_tree.predict(X_test)\n",
    "print_classification_report(value_test=y_test,pred=predict)\n",
    "print_matrix_confusion(value_test=y_test,pred=predict)\n",
    "list_acuracy_score.append(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliação dos resultados do modelo:**\n",
    " - Acurácia: O algoritmo *decision tree* apresentou um resultado ótimo de acurácia 0.96\n",
    " - Precisão: O algoritmo algoritmo *decision tree* apresentou como correta para 0 0.98 e para 1 0.45        \n",
    " - Recall:   O algoritmo *decision tree* apresentou como correta para 0: 0.98 e para 1:0.43\n",
    " - f1 score: O algoritmo *decision tree* apresentou como média harmonica: 0.98 para 0.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train) \n",
    "predict = random_forest.predict(X_test)\n",
    "print_classification_report(y_test, predict)\n",
    "print_matrix_confusion(y_test, predict)\n",
    "list_acuracy_score.append(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliação dos resultados do modelo:**\n",
    " - Acurácia: O algoritmo *random forest* apresentou um resultado ótimo de acurácia 0.98\n",
    " - Precisão: O algoritmo *random forest* apresentou como correta para 0 0.98 e para 1 1.00        \n",
    " - Recall:   O algoritmo *random forest* apresentou como correta para 0: 1.00 e para 1:0.30\n",
    " - f1 score: O algoritmo *random forest* apresentou como média harmonica: 0.99 para 0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = GradientBoostingClassifier()\n",
    "gradient.fit(X_train, y_train)\n",
    "predict = gradient.predict(X_test)\n",
    "print_classification_report(y_test, predict)\n",
    "print_matrix_confusion(y_test, predict)\n",
    "list_acuracy_score.append(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "predict = xgb.predict(X_test)\n",
    "print_classification_report(y_test,predict)\n",
    "print_matrix_confusion(y_test, predict)\n",
    "ada_boost = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ada_boost.fit(X_train, y_train)\n",
    "predict = ada_boost.predict(X_test)\n",
    "print_classification_report(y_test, predict)\n",
    "print_matrix_confusion(y_test, predict)\n",
    "list_acuracy_score.append(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliação dos resultados do modelo:**\n",
    " - Acurácia: O algoritmo *gradient boosting* apresentou um resultado ótimo de acurácia 0.97\n",
    " - Precisão: O algoritmo *gradient boosting* apresentou como correta para 0 0.98 e para 1 0.77        \n",
    " - Recall:   O algoritmo *gradient boosting* apresentou como correta para 0: 1.00 e para 1:0.29\n",
    " - f1 score: O algoritmo *gradient boosting* apresentou como média harmonica: 0.99 para 0.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "predict = knn.predict(X_test)\n",
    "print_classification_report(y_test, predict)\n",
    "print_matrix_confusion(y_test, predict)\n",
    "list_acuracy_score.append(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliação dos resultados do modelo:**\n",
    " - Acurácia: O algoritmo *knn* apresentou um resultado ótimo de acurácia 0.98\n",
    " - Precisão: O algoritmo *knn* apresentou como correta para 0 0.98 e para 1 0.45        \n",
    " - Recall:   O algoritmo *knn* apresentou como correta para 0: 0.98 e para 1:0.37\n",
    " - f1 score: O algoritmo *knn* apresentou como média harmonica: 0.98 para 0.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acuracy_score\n",
    "modelo = ['BernoulliNB','ComplementNB','MultinomialNB','SVC',\n",
    "          'DecisionTreeClassifier','RandomForestClassifier','GradientBoostingClassifier',\n",
    "          'XGBClassifier','KNeighborsClassifier']\n",
    "y_pos = np.arange(len(modelo))\n",
    "y_val = [ x for x in list_acuracy_score]\n",
    "\n",
    "plt.figure(figsize=(35, 15))\n",
    "plt.bar(y_pos,y_val, align='center', alpha=0.7)\n",
    "plt.xticks(y_pos, modelo)\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Accuracy of Models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
